---
layout: post
title: "Hadoop 分布式系统搭建"
description: "Hadoop Fully-Distributed "
categories: 技术 java 分布式
tags: [hadoop, java, HDFS]
---
{% include JB/setup %}

最近重新把Hadoop Fully-Distributed 搭起来，在此做个记录

都说Hadoop平台配置很容易出问题，我配置的过程中到没出什么问题。只要细心，还是很容易搭建起来了的。

##Hadoop平台配置


## **1. 环境**   

* JDK1.6  
* Hadoop，我下的是stable的，hadoop-1.2.1.tar.gz。  

解压hadoop包，随便放到什么地方。配置JAVA_HOME，在conf/hadoop-env.sh中：  
把

    # The java implementation to use.  Required.
    # export JAVA_HOME=/usr/lib/j2sdk1.5-sun
  
改为

    # The java implementation to use.  Required.
    export JAVA_HOME=/usr/local/jvm/jdk/jdk1.6.0_45/（这里配置自己的java_home路径）

## **2. 集群配置**   

我使用的是一台master和一台slave两台机器。本机ubuntu12.04，vmbox中装的也是ubuntu12.04，网络使用桥接模式，两台机器都装
open-ssh，调试好两台机器的通信就可以开始配置了，首先在master上配置好，再copy到slave，稍作修改。  
两台机器如下： 括号中的是机器名，下面配置中要用到  
**master(alex-Lenovo-IdeaPad-Y470)**  
**slave(qct-VirtualBox)**  

###1.对于master(alex-Lenovo-IdeaPad-Y470):  

(1) 在hadoop根目录下建几个文件夹：   

    mkdir tmp  
    mkdir hdfs  
    mkdir hdfs/name  
    mkdir hdfs/data  

(2) 在conf目录中，编辑以下3个文件：**core-site.xml** **hdfs-site.xml** **mapred-site.xml**  

**core-site.xml**:  

    <configuration>
        <property>
            <name>fs.default.name</name>
            <value>hdfs://alex-Lenovo-IdeaPad-Y470:9000</value>
        </property>
        <property>
            <name>hadoop.tmp.dir</name>
            <value>/usr/local/development/hadoop-1.2.1/tmp</value>
        </property>
    </configuration>
**hdfs-site.xml**:  

    <configuration>
        <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>
        <property>
            <name>dfs.name.dir</name>
            <value>/usr/local/development/hadoop-1.2.1/hdfs/name</value>
        </property>
        <property>
            <name>dfs.data.dir</name>
            <value>/usr/local/development/hadoop-1.2.1/hdfs/data</value>
        </property>
    </configuration>
**mapred-site.xml**:  

    <configuration>
         <property>
             <name>mapred.job.tracker</name>
             <value>alex-Lenovo-IdeaPad-Y470:9001</value>
         </property>
    </configuration>

(3) master slave文件配置，在conf目录下，配置masters和slaves文件  

masters：  
    alex-Lenovo-IdeaPad-Y470  

slaves:  
    qct-VirtualBox  

###2.对于slave(qct-VirtualBox):   

同样创建在master上创建的那几个目录，然后拷贝上面配置好的三个文件到slave机器对应目录覆盖原来的。修改机器名为slave的机器名。拷贝命令可以用scp:  

    scp core-site.xml qct-VirtualBox:/usr/local/development/hadoop-1.2.1/conf  

###3.host配置  

**master** 中：  

    192.168.0.90    alex-Lenovo-IdeaPad-Y470
    192.168.0.103   qct-VirtualBox

**slave** 中：  

    192.168.0.90    alex-Lenovo-IdeaPad-Y470
    192.168.0.103   qct-VirtualBox

因为我只有两台机器，所以master和slave的host配置一样，如果有多台slave，则**master中要配置所有slave机器的ip和机器名，而slave中只配置自身和master**。  

###4.设置 passphraseless ssh  

master必须要能 以无密码方式ssh到slave。  

    $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa   
    $ ssh-copy-id -i ~/.ssh/id_dsa.pub qct@qct-VirtualBox  

测试下ssh到slave是不是不需要密码  

###5.启动Hadoop集群  

(1)格式化HDFS：在master上运行: $ bin/hadoop namenode -format  

(2)启动：  
在master上运行：$ bin/start-all.sh  
可以在master和slave上运行java的jps命令,查看开启的java daemons：  
此时，master机器上应当有namenode，jobtracker，secondarynamenode，而slave机器上有datanode，tasktracker  

(3)检查是否正常：  
http://127.0.0.1:50070/和http://127.0.0.1:50030/分别查看HDFS和job tracker状态。  
其中HDFS最容易出问题。如果 Live Nodes:0 ，HDFS有问题，回去检查配置文件。


